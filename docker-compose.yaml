version: "3.7"

x-base: &base
  restart: unless-stopped
  networks:
    elastic: {}
  healthcheck:
    disable: false
    test: [ "CMD-SHELL", "echo"]
    interval: 10s
    timeout: 5s
    retries: 3
    start_period: 20s
  deploy:
    replicas: 1

networks:
  elastic:

services:
  es_init_certs:
    <<: *base
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_STACK_VERSION:-7.13.1}
    entrypoint:
      - bash
      - -c 
      - |
        if [ ! -f /certs/bundle.zip ]; then
          bin/elasticsearch-certutil cert --silent --pem --in config/certificates/instances.yaml -out /certs/bundle.zip;
          unzip /certs/bundle.zip -d /certs;
        else
          echo cert exists, skip
        fi;
        chown -R 1000:0 /certs
        echo exit
    restart: on-failure
    working_dir: /usr/share/elasticsearch
    volumes:
      - ./certs/:/certs
      - ./certs/:/usr/share/elasticsearch/config/certificates
    healthcheck:
      disable: true
  elasticsearch1:
    <<: *base
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_STACK_VERSION:-7.13.1}
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ES_HEAP_OPTS=${ES_HEAP_OPTS}
      - node.name=elasticsearch1
      - cluster.max_shards_per_node=10000
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - network.host=0.0.0.0
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/elasticsearch1/elasticsearch1.key
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.http.ssl.certificate=certs/elasticsearch1/elasticsearch1.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.verification_mode=certificate 
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.certificate=certs/elasticsearch1/elasticsearch1.crt
      - xpack.security.transport.ssl.key=certs/elasticsearch1/elasticsearch1.key
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - ./data/es:/usr/share/elasticsearch/data
      - ./certs:/usr/share/elasticsearch/config/certs
    ports:
      - 9200:9200
    depends_on:
      es_init_certs: 
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD-SHELL", "curl -k https://localhost:9200/_cat/health"]
    mem_limit: ${ES_MEM_LIMIT}
  kibana:
    <<: *base
    image: docker.elastic.co/kibana/kibana:${ELASTIC_STACK_VERSION:-7.13.1}
    environment:
      - ELASTICSEARCH_HOSTS=https://elasticsearch1:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - SERVER_SSL_ENABLED=true
      - SERVER_SSL_KEY=/certs/kibana/kibana.key
      - SERVER_SSL_CERTIFICATE=/certs/kibana/kibana.crt
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=/certs/ca/ca.crt
      - ELASTICSEARCH_SSL_VERIFICATIONMODE=certificate
    volumes:
      - ./certs:/certs
    ports:
      - 5601:5601
  zookeeper1:
    <<: *base
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION:-7.1.4}
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
     - "2181:2181"
    mem_limit: ${ZK_MEM_LIMIT}
  zoonavigator:
    <<: *base
    image: elkozmon/zoonavigator:${ZOONAVIGATOR_VERSION}
    ports:
      - "8000:8000"
    environment:
      HTTP_PORT: 8000
      AUTO_CONNECT_CONNECTION_STRING: zookeeper1:2181
    depends_on:
      - zookeeper1
    deploy:
      replicas: 0
  kafka1:
    <<: *base
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION:-7.1.4}
    depends_on:
      - zookeeper1
    ports:
      - "9092:9092"
      - "9991:9991"
    environment:
      KAFKA_BROKER_ID: 101
      KAFKA_JMX_PORT: 9991
      KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_NUM_PARTITIONS: 10
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka1:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper1:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      KAFKA_HEAP_OPTS: ${KAFKA_BROKER_HEAP_OPTS}
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9092"]
    mem_limit: ${KAFKA_BROKER_MEM_LIMIT:-600m}
  kafdrop:
    <<: *base
    image: obsidiandynamics/kafdrop:3.30.0
    ports:
      - "9990:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka1:29092"
      JVM_OPTS: -Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify
    depends_on:
      - kafka1
    deploy:
      replicas: 0
    mem_limit: ${KAFDROP_MEM_LIMIT:-200m}
  filebeat:
    <<: *base
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION:-7.16.2}
    hostname: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yaml:/usr/share/filebeat/filebeat.yml
      - ./data/filebeat:/usr/share/filebeat/data
      - ./logs:/tmp/var/logs
    command: ["--strict.perms=false"]
    ports:
      - "514:514/tcp"
      - "514:514/udp"
    depends_on:
      - kafka1
    deploy:
      mode: global
      replicas: 0
  metricbeat:
    <<: *base
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-7.13.1}
    # https://github.com/docker/swarmkit/issues/1951
    hostname: metricbeat
    user: root
    volumes:
      - ./metricbeat/metricbeat.yaml:/usr/share/metricbeat/metricbeat.yml:ro
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/metricbeat:/usr/share/metricbeat/data
    environment:
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST:-elasticsearch1}
      - KIBANA_HOST=${KIBANA_HOST:-kibana}
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-elastic}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-password}
    command: ["--strict.perms=false", "-system.hostfs=/hostfs"]
    deploy:
      mode: global
      replicas: 0
  logstash:
    <<: *base
    image: docker.elastic.co/logstash/logstash:${ELASTIC_STACK_VERSION:-7.13.1}
    volumes:
      - ./logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./logstash/pipelines:/usr/share/logstash/pipelines:ro
      - ./logstash/patterns:/usr/share/logstash/config/patterns:ro
      - ./certs:/usr/share/logstash/certs:ro
    ports:
      - "5000:5000"
    environment:
      LS_JAVA_OPTS: ${LS_HEAP_OPTS}
    depends_on:
      - elasticsearch1
    deploy:
      replicas: 0
    mem_limit: ${LS_MEM_LIMIT:-500m}
  infini-console:
    <<: *base
    image: infinilabs/console:${INFINI_CONSOLE_VERSION:-centos-0.6.0-841}
    volumes:
      - ./infini/console.yaml:/console.yml:ro
    ports:
      - "9002:9000"
    deploy:
      replicas: 1